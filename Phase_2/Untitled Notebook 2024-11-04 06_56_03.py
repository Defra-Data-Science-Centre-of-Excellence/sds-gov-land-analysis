# Databricks notebook source
dbutils.fs.mkdirs('dbfs:/mnt/lab/restricted/ESD-Project/Defra_Land/Layers/Input/NE_Marine/')

# COMMAND ----------

dbutils.fs.cp('dbfs:/FileStore/miles_clement/','dbfs:/mnt/lab/restricted/ESD-Project/Defra_Land/Layers/Input/NE_Marine/', True)

# COMMAND ----------

dbutils.fs.rm('dbfs:/dbfs', True)

# COMMAND ----------

ExecutionError: An error occurred while calling o405.mv.
: org.apache.hadoop.fs.PathIOException: `/7741051004437205/dbfs/mnt/lab/restricted/ESD-Project/Defra_Land/tif_outputs/dgl_woodland_sparse_sum_021224.tif': Input/output error: Parallel access to the create path detected. Failing request to honor single writer semantics
	at shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.checkException(AzureBlobFileSystem.java:1719)
	at shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.create(AzureBlobFileSystem.java:399)
	at com.databricks.common.filesystem.LokiFileSystem.create(LokiFileSystem.scala:257)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.$anonfun$create$3(DatabricksFileSystemV2.scala:931)
	at com.databricks.s3a.S3AExceptionUtils$.convertAWSExceptionToJavaIOException(DatabricksStreamUtils.scala:66)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.$anonfun$create$2(DatabricksFileSystemV2.scala:928)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.$anonfun$withUserContextRecorded$2(DatabricksFileSystemV2.scala:1378)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionContext(DatabricksFileSystemV2.scala:745)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionTags(DatabricksFileSystemV2.scala:745)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withUserContextRecorded(DatabricksFileSystemV2.scala:1353)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.$anonfun$create$1(DatabricksFileSystemV2.scala:927)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionContext(DatabricksFileSystemV2.scala:745)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.withAttributionTags(DatabricksFileSystemV2.scala:745)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperationWithResultTags(DatabricksFileSystemV2.scala:745)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.recordOperation(DatabricksFileSystemV2.scala:745)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystemV2.create(DatabricksFileSystemV2.scala:927)
	at com.databricks.backend.daemon.data.client.DatabricksFileSystem.create(DatabricksFileSystem.scala:142)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1233)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1210)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1091)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:489)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:430)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:368)
	at com.databricks.backend.daemon.dbutils.FSUtils.cpRecursive(DBUtilsCore.scala:477)
	at com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$mv$3(DBUtilsCore.scala:414)
	at com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$withMvSafetyChecks$2(DBUtilsCore.scala:229)
	at com.databricks.backend.daemon.dbutils.FSUtils.withFsSafetyCheck(DBUtilsCore.scala:151)
	at com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$withMvSafetyChecks$1(DBUtilsCore.scala:183)
	at com.databricks.backend.daemon.dbutils.FSUtils.withFsSafetyCheck(DBUtilsCore.scala:151)
	at com.databricks.backend.daemon.dbutils.FSUtils.withMvSafetyChecks(DBUtilsCore.scala:183)
	at com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$mv$2(DBUtilsCore.scala:411)
	at com.databricks.backend.daemon.dbutils.FSUtils.checkPermission(DBUtilsCore.scala:146)
	at com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$mv$1(DBUtilsCore.scala:411)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)
	at com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)
	at com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)
	at com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)
	at com.databricks.backend.daemon.dbutils.FSUtils.mv(DBUtilsCore.scala:410)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:306)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: Parallel access to the create path detected. Failing request to honor single writer semantics
	at shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.conditionalCreateOverwriteFile(AzureBlobFileSystemStore.java:723)
	at shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.createFile(AzureBlobFileSystemStore.java:655)
	at shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.create(AzureBlobFileSystem.java:393)
	... 81 more
